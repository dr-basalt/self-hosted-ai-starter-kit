# Self-Hosted AI Starter Kit

ğŸš€ **Kit de dÃ©marrage complet pour l'IA auto-hÃ©bergÃ©e** avec OpenWebUI, Ollama, Qdrant, N8N et PostgreSQL.

## âœ¨ FonctionnalitÃ©s

- **ğŸ¤– OpenWebUI Bundle** : Interface web moderne pour interagir avec les LLMs
- **ğŸ§  MÃ©moire persistante** : Stockage vectoriel avec Qdrant et sÃ©parateur tenant `<email>:`
- **ğŸ¤ STT/TTS OpenAI** : Reconnaissance et synthÃ¨se vocale via API OpenAI
- **ğŸ” HTTPS Let's Encrypt** : Certificats SSL automatiques
- **ğŸ“Š Persistance complÃ¨te** : Toutes les donnÃ©es sauvegardÃ©es dans des volumes Docker
- **âš¡ ModÃ¨les optimisÃ©s** : Configuration automatique des paramÃ¨tres pour Llama2, Phi-3, Gemma2
- **ğŸ”§ N8N** : Automatisation des workflows
- **ğŸ—„ï¸ PostgreSQL** : Base de donnÃ©es relationnelle

## ğŸš€ Installation rapide

### PrÃ©requis
- Docker et Docker Compose v2
- Python 3.8+
- Domaine configurÃ© (pour Let's Encrypt)

### 1. Cloner le repository
```bash
git clone https://github.com/dr-basalt/self-hosted-ai-starter-kit.git
cd self-hosted-ai-starter-kit
```

### 2. Configuration initiale
```bash
# Configuration complÃ¨te avec CPU
./launcher.sh cpu --setup --configure --letsencrypt

# Ou Ã©tape par Ã©tape
./launcher.sh cpu --setup
./launcher.sh cpu --configure
./launcher.sh cpu --letsencrypt
```

### 3. Configuration des variables d'environnement
```bash
cp env.example .env
# Ã‰diter .env avec vos clÃ©s API et domaines
```

## ğŸ“‹ Configuration

### Variables d'environnement importantes

```bash
# OpenAI API (requis pour STT/TTS)
OPENAI_API_KEY=your-openai-api-key-here

# Let's Encrypt
LETSENCRYPT_EMAIL=admin@votre-domaine.com
LETSENCRYPT_DOMAIN=votre-domaine.com

# SÃ©curitÃ©
WEBUI_SECRET_KEY=your-secret-key-here
```

### Profils disponibles

- **CPU** : `./launcher.sh cpu` - Pour serveurs sans GPU
- **GPU NVIDIA** : `./launcher.sh gpu` - Pour serveurs avec GPU NVIDIA
- **GPU AMD** : `./launcher.sh gpu-amd` - Pour serveurs avec GPU AMD

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenWebUI     â”‚    â”‚     Ollama      â”‚    â”‚     Qdrant      â”‚
â”‚   (Bundle)      â”‚â—„â”€â”€â–ºâ”‚   (LLM API)     â”‚    â”‚  (Vector DB)    â”‚
â”‚   Port: 3000    â”‚    â”‚   Port: 11434   â”‚    â”‚   Port: 6333    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      N8N        â”‚    â”‚   PostgreSQL    â”‚    â”‚   Let's Encrypt â”‚
â”‚  (Workflows)    â”‚    â”‚   (Database)    â”‚    â”‚   (SSL Certs)   â”‚
â”‚   Port: 5678    â”‚    â”‚   Port: 5432    â”‚    â”‚   Auto-renewal  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§  MÃ©moire et Embeddings

### Configuration automatique
- **ModÃ¨le d'embedding** : `all-MiniLM-L6-v2` (optimisÃ© pour la performance)
- **SÃ©parateur tenant** : `:` (format: `<email>:contenu`)
- **Collection Qdrant** : `openwebui_memory`
- **Seuil de similaritÃ©** : 0.7
- **RÃ©sultats max** : 10

### Exemple d'utilisation
```python
# Les conversations sont automatiquement vectorisÃ©es
# avec le format: user@example.com:contenu du message
# Permettant l'isolation des donnÃ©es par utilisateur
```

## ğŸ¤ Configuration STT/TTS

### OpenAI API (recommandÃ©)
- **STT** : Whisper-1 pour la reconnaissance vocale
- **TTS** : TTS-1 avec voix "alloy"
- **Formats supportÃ©s** : WAV, MP3, M4A, WebM

### Configuration automatique
Le script `configure-models.py` configure automatiquement :
- Les paramÃ¨tres optimisÃ©s pour chaque modÃ¨le
- Les templates de prompts
- Les sÃ©quences d'arrÃªt
- Les permissions utilisateur

## ğŸ” SÃ©curitÃ© HTTPS

### Let's Encrypt automatique
- **Certificats SSL** : GÃ©nÃ©ration automatique
- **Renouvellement** : Tous les jours Ã  12h00
- **Domaine** : Configurable via `LETSENCRYPT_DOMAIN`
- **Email** : Configurable via `LETSENCRYPT_EMAIL`

### Installation manuelle
```bash
./setup-letsencrypt.sh votre-domaine.com votre-email@domaine.com
```

## ğŸ“Š Persistance des donnÃ©es

### Volumes Docker
- `openwebui_data` : DonnÃ©es utilisateur et conversations
- `openwebui_uploads` : Fichiers uploadÃ©s
- `openwebui_logs` : Logs d'application
- `qdrant_data` : Base vectorielle
- `ollama_data` : ModÃ¨les LLM
- `postgres_data` : Base de donnÃ©es
- `n8n_data` : Workflows N8N
- `letsencrypt_certs` : Certificats SSL

### Sauvegarde
```bash
# Sauvegarder toutes les donnÃ©es
docker compose down
tar -czf backup-$(date +%Y%m%d).tar.gz \
  $(docker volume inspect -f '{{.Mountpoint}}' \
    openwebui_data openwebui_uploads qdrant_data \
    ollama_data postgres_data n8n_data)
```

## ğŸ”§ ModÃ¨les LLM optimisÃ©s

### Configuration automatique
Le script configure automatiquement les paramÃ¨tres optimisÃ©s :

| ModÃ¨le | Temperature | Top-P | Max Tokens | Context |
|--------|-------------|-------|------------|---------|
| Llama2 | 0.7 | 0.9 | 2048 | 4096 |
| Phi-3 | 0.8 | 0.95 | 4096 | 8192 |
| Gemma2 | 0.6 | 0.85 | 3072 | 6144 |

### Templates de prompts
- **Llama2** : `<s>[INST] {prompt} [/INST]`
- **Phi-3** : `<|user|>\n{prompt}<|end|>\n<|assistant|>`
- **Gemma2** : `<start_of_turn>user\n{prompt}<end_of_turn>\n<start_of_turn>model\n`

## ğŸš€ Commandes utiles

### Gestion des services
```bash
# DÃ©marrer tous les services
./launcher.sh cpu

# Voir les logs
docker compose logs -f openwebui

# RedÃ©marrer un service
docker compose restart openwebui

# ArrÃªter tous les services
docker compose down

# Nettoyer les volumes (âš ï¸ supprime toutes les donnÃ©es)
docker compose down -v
```

### Configuration
```bash
# Configuration complÃ¨te
./launcher.sh cpu --setup --configure --letsencrypt

# Configuration manuelle des modÃ¨les
python3 configure-models.py

# Configuration Let's Encrypt manuelle
./setup-letsencrypt.sh domaine.com email@domaine.com
```

### Monitoring
```bash
# Statut des services
docker compose ps

# Utilisation des ressources
docker stats

# Logs en temps rÃ©el
docker compose logs -f
```

## ğŸ” DÃ©pannage

### ProblÃ¨mes courants

#### OpenWebUI ne dÃ©marre pas
```bash
# VÃ©rifier les logs
docker compose logs openwebui

# VÃ©rifier la configuration
docker compose config

# RedÃ©marrer le service
docker compose restart openwebui
```

#### ProblÃ¨mes de mÃ©moire Qdrant
```bash
# VÃ©rifier la connexion
curl http://localhost:6333/health

# RedÃ©marrer Qdrant
docker compose restart qdrant
```

#### Certificats Let's Encrypt
```bash
# VÃ©rifier les certificats
openssl x509 -in /app/certs/cert.pem -text -noout

# Renouveler manuellement
certbot renew
```

### Logs et debugging
```bash
# Logs dÃ©taillÃ©s
docker compose logs -f --tail=100 openwebui

# Shell dans le conteneur
docker compose exec openwebui bash

# VÃ©rifier les variables d'environnement
docker compose exec openwebui env | grep -E "(OLLAMA|QDRANT|MEMORY)"
```

## ğŸ“ˆ Performance

### Recommandations systÃ¨me
- **CPU** : 4+ cÅ“urs pour les modÃ¨les de base
- **RAM** : 8GB minimum, 16GB recommandÃ©
- **Stockage** : 50GB+ pour les modÃ¨les et donnÃ©es
- **GPU** : Optionnel mais recommandÃ© pour les gros modÃ¨les

### Optimisations
- **Embeddings** : `all-MiniLM-L6-v2` (384 dimensions, rapide)
- **Qdrant** : Indexation automatique des vecteurs
- **Ollama** : Chargement Ã  la demande des modÃ¨les
- **OpenWebUI** : Bundle prÃ©-compilÃ© (pas de build)

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ™ Remerciements

- [OpenWebUI](https://github.com/open-webui/open-webui) - Interface web moderne
- [Ollama](https://ollama.ai/) - Serveur LLM local
- [Qdrant](https://qdrant.tech/) - Base de donnÃ©es vectorielle
- [N8N](https://n8n.io/) - Automatisation des workflows

---

**ğŸ¯ Objectif** : Fournir une solution complÃ¨te et prÃªte Ã  l'emploi pour l'IA auto-hÃ©bergÃ©e avec une configuration optimisÃ©e et une persistance des donnÃ©es.
